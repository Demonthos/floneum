[package]
name = "kalosm"
edition = "2021"
version = "0.2.2"
authors = ["Evan Almloff"]
description = "A simple interface for pretrained AI models "
keywords = ["llm", "llama", "whisper", "ocr", "nlp"]
license = "MIT/Apache-2.0"
repository = "https://github.com/floneum/floneum"

[dependencies]
anyhow = "1.0.75"
async-trait = "0.1.74"
comfy-table = "7.1.0"
futures-util = "0.3.28"
hdrhistogram = "7.5.4"
image = "0.24.7"
num-traits = "0.2.17"
once_cell = "1.19.0"
rand = "0.8.5"

[dependencies.kalosm-common]
version = "0.1.0"
path = "../kalosm-common"
features = []

[dependencies.kalosm-language]
features = []
optional = true
workspace = true

[dependencies.kalosm-sound]
features = []
optional = true
workspace = true

[dependencies.kalosm-streams]
features = []
workspace = true

[dependencies.kalosm-vision]
features = []
optional = true
workspace = true

[dependencies.llm-samplers]
features = []
workspace = true

[dependencies.serde]
version = "1.0.163"
features = ["derive"]

[dependencies.surrealdb]
version = "1.1.1"
features = ["kv-rocksdb"]
optional = true

[dependencies.tokio]
version = "1.32.0"
features = ["full", "macros", "rt-multi-thread"]

[dependencies.tracing]
version = "0.1.40"
features = ["std"]
default-features = false

[dev-dependencies]
axum = "0.7.2"
ego-tree = "0.6.2"
scraper = "0.18.1"
tokenizers = "0.15.0"
tracing-subscriber = "0.2"

[dev-dependencies.candle-core]
features = []
workspace = true

[dev-dependencies.candle-datasets]
features = []
workspace = true

[dev-dependencies.candle-nn]
features = []
workspace = true

[dev-dependencies.candle-transformers]
features = []
workspace = true

[dev-dependencies.kalosm-llama]
features = []
workspace = true

[features]
cublas = ["kalosm-language/cublas"]
default = ["language", "sound", "vision", "surrealdb"]
language = ["kalosm-language"]
llamacpp = ["kalosm-language/llamacpp"]
metal = ["kalosm-language/metal", "kalosm-vision/metal", "kalosm-sound/metal"]
sound = ["kalosm-sound"]
surrealdb = ["dep:surrealdb"]
vision = ["kalosm-vision"]
