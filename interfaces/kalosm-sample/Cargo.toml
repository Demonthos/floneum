[package]
name = "kalosm-sample"
version = "0.2.1"
edition = "2021"
description = "A common interface for token sampling and helpers for structered llm sampling "
license = "MIT/Apache-2.0"
repository = "https://github.com/floneum/floneum"
authors = ["Evan Almloff"]
keywords = ["ai", "llm", "llama", "mistral", "nlp"]

[dependencies]
llm-samplers = { workspace = true }
rand = "0.8.5"
anyhow = "1.0.71"
tracing = "0.1.37"
candle-core.workspace = true
tokenizers = { version = "0.19.1" }
rustc-hash = "1.1.0"
regex-automata = "0.4.5"
thiserror = "1.0.58"
kalosm-parse-macro = { workspace = true }

[dev-dependencies]
tracing-subscriber = "0.3.18"
criterion = "0.5.1"

[[bench]]
name = "parse"
harness = false

